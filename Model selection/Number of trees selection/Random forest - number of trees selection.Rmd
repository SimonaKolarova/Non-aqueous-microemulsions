---
output:
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, cache = TRUE, warning=FALSE, message=FALSE)
```

```{r libraries, echo = FALSE}
library(tidyverse)
library(reshape)
library(ggpubr)
library(caret)
library(randomForest)
library(pROC)
library(corrplot)
```

### Scripts
```{r r scripts}
source("Predictive performance assessment.R", local = knitr::knit_global())
source("Statistical analysis.R", local = knitr::knit_global())
```

### Dataset
``` {r data}
PB_predictors <- read.csv("Data/Phase behaviour and descriptors (25 pc step).csv")
```

The  dataset was split into a training/testing (`TT_data`) and a validation dataset comprising 21 and 7 phase diagrams, respectively. Only the training/testing dataset was used in the selection of the random forest structure (*i.e.*, number of trees).
``` {r data splitting}
TT_data <- filter(PB_predictors, Set == "Training")
```

A list of all phase behaviour predictor names was created and the phase behaviour variable was encoded as a factor.
``` {r data definitions}
predictors_all<-colnames(TT_data[,3:66][,-(4:6)])
TT_data$Phase.behaviour<-factor(as.character(TT_data$Phase.behaviour))
```

### Random forest - number of trees selection

#### Random forest algorithm 
First, the function used to train and evaluated the random forest models was defined.
```{r random forest algorithm}
run_random_forest <- function(training_testing_data, predictors, model_performance, model_name, model_number, trees) {
  
  # Training parameters
  PMsummary <- function(...) c(twoClassSummary(...), defaultSummary(...))
  trainCtrl <- trainControl(method = "cv", number = 10,
                            summaryFunction = PMsummary, classProbs = TRUE)
  
  # Tuning
  mtryValues <- c(round(length(predictors)/5),
                  round(length(predictors)*2/5),
                  round(length(predictors)*3/5),
                  round(length(predictors)*4/5),
                  length(predictors))

  # TT_data spliting 
  trainIndex <- createDataPartition(training_testing_data$Phase.behaviour, p = .7, list = FALSE)
  training_data <- training_testing_data[ trainIndex,]
  testing_data <- training_testing_data[ -trainIndex,]
  
  # Model training
  rf_model <- train(training_data[,predictors],
                       training_data$Phase.behaviour, 
                       method = "rf",
                       ntree = trees, 
                       metric = "ROC",
                       tuneGrid = data.frame(mtry = mtryValues),
                       trControl = trainCtrl)
  
  
  # Model performance assessement
  model_performance <- model_performance_assessment(testing_data, predictors, model_performance, rf_model, model_name, model_number)

  return(model_performance)
}  
```

#### Random forest models training and evaluation
Eight types random forest models (n=10) comprising a varying number of trees were trained and evaluated.
```{r results dataframe, echo = FALSE}
# Model performance dataframe
model_performance_trees <- data.frame(matrix(ncol = 8, nrow = 80))
colnames(model_performance_trees) <- c("Model", "AUC", "Accuracy", "Kappa", "Sensitivity", "Specificity", "Precision", "Fscore")
```

```{r trees numbers}
trees_list <- c(1, 5, 10, 50, 100, 500, 1000, 5000)
```
```{r rf models}
for (i in 1:length(trees_list)) {
  for (j in 1:10) {
    model_number = (i-1)*10+j
    model_name = paste("RF", trees_list[i])
    model_performance_trees <- run_random_forest(TT_data, predictors_all, model_performance_trees, model_name, model_number, trees_list[i])
  }
}
```

#### Random forest models performance comparison
The prediction perfromance of the four models on the testing data (randomly selected 30% of `TT_data`, which was not used for training) was visually assessed using the various perfromance metrics.

```{r melt, echo = FALSE}
model_performance_melt_1 <- melt(model_performance_trees[-c(2,5,6,7,8)], value.name = "Model")
model_performance_melt_2 <- melt(model_performance_trees[-c(2,3,4,7,8)], value.name = "Model")
model_performance_melt_3 <- melt(model_performance_trees[-c(2,3,4,5,6)], value.name = "Model")
```

```{r models plot 1, fig.height=12, fig.width=10, echo=FALSE}
mp1 <- ggplot(model_performance_melt_1, aes(x = Model, y = value,  color = Model)) + 
  geom_boxplot() +
  facet_grid(cols = vars(variable)) +
  scale_x_discrete(limits= paste("RF", trees_list)) +
  ylim(0.85,1) +
  labs(title = "Predictive performance of random forest models on testing data",
       y = "Performance") +
  scale_color_brewer(palette = "Set2") +
  theme_classic() + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")

mp2 <- ggplot(model_performance_melt_2, aes(x = Model, y = value,  color = Model)) + 
  geom_boxplot() +
  facet_grid(cols = vars(variable)) +
  scale_x_discrete(limits= paste("RF", trees_list)) +
  ylim(0.92,1) +
  labs(y = "Performance") +
  scale_color_brewer(palette = "Set2") +
  theme_classic() + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")

mp3 <- ggplot(model_performance_melt_3, aes(x = Model, y = value,  color = Model)) + 
  geom_boxplot() +
  facet_grid(cols = vars(variable)) +
  scale_x_discrete(limits= paste("RF", trees_list)) +
  ylim(0.92,1) +
  labs(y = "Performance") +
  scale_color_brewer(palette = "Set2") +
  theme_classic() + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")

ggarrange(mp1, mp2, mp3, 
          ncol = 1, nrow = 3)
```

The results suggest that the number of trees comprising the random forests affects the models' predictive performance. Specifically, models incorporating few trees (*i.e.*, less than 50) generally exhibit a comparatively lower prediction performance on the training data and so does the model employing the most trees (*i.e.*, 5000), likely due to data overfitting. Random forests comprising between 50 and 1000 trees appear to perform equally well.  

### Number of trees selection using AUC metric
To select the best random forest model structure for the phase behaviour classification problem, the area under the receiver operating characteristic (ROC) curve (AUC) for the predictions of the eigth investigated model structures on the testing data (*i.e.*, 30% of `TT_data`, which was not used for training) was compared.

**Visual comparison** <br>
```{r rf models plot, fig.height=4, fig.width=10, echo = FALSE}
ggplot(model_performance_trees, aes(x = Model, y=AUC)) + 
  geom_boxplot() + 
  scale_x_discrete(limits=paste("RF", trees_list))  +
  ylim(0.92,1) +
  labs(title = "Random forest models trained using different numbers of trees",
       y = "Area under the ROC curve (AUC)") +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5))
```

**Statistical comparison** <br>
```{r rf models testing statistics, echo = FALSE}
run_statistical_analysys(model_performance_trees, model_performance_trees$AUC, model_performance_trees$Model)
```

**The four model structures employing 50, 100, 500 or 1000 decision trees all performed equally well. The average AUC for these model types (n = 10) was between 0.9688 ± 0.004 and 0.9699 ± 0.003 and the differences between them were not statistically significant with the corresponding p-values ranging between 0.998 and 1.**
<br><br>
**Conversely, the two models comprising the smallest number of trees (*i.e.*, 1 and 5) both performed statistically significantly worse than all models comprising 50 to 1000 trees (p-values between 0 and 0.006).**
<br><br>
**Lastly, the models comprising 10 and 5000 decision trees had an average AUC of 0.9675 ± 0.003 and 0.9679 ± 0.003, respectively, suggesting their prediction performance on the training data is sligtly worse than the four models employing 50 to 1000 trees, however, not statistically significantly so (p-values between 0.856 and 0.999).**
<br><br>
**To reduce the computational demand of the following feature selection steps, while not decreasing the predictive performance of the algorithm, the random forest structure comprising 50 decision trees was selected to carry forward.**
```{r export, echo = FALSE}
write.csv(model_performance_trees, "Results/Model performance (tree number).csv", row.names = FALSE)
```
